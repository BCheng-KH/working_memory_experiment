{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 20:54:12.897448: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-22 20:54:12.927372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-22 20:54:13.396944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-22 20:54:13.697865: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from working_memory_model import WorkingMemoryModel\n",
    "import random\n",
    "from tensorflow.keras import activations, losses\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 20:50:22.805792: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_gpu_support()\n",
    "tf.test.gpu_device_name()\n",
    "#import nvidia.cudnn;print(nvidia.cudnn.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_test_functions import training_loop_association, make_association_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bits = 5\n",
    "num_comb = 2\n",
    "reserved_combs = [set([3, 4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WorkingMemoryModel([8, 16, 32, 32, 16, num_bits], learning_rate=0.0002, do_initial_relu=False, do_final_sigmoid=True, do_hebbian_learning=True)\n",
    "model2 = WorkingMemoryModel([8, 16, 32, 32, 16, num_bits], learning_rate=0.0002, do_initial_relu=False, do_final_sigmoid=True, do_hebbian_learning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling WorkingMemoryModel.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <InnerMemoryLayer name=inner_memory_layer, built=True> (of type <class 'inner_memory_layer.InnerMemoryLayer'>)\u001b[0m\n\nArguments received by WorkingMemoryModel.call():\n  • inputs=tf.Tensor(shape=(24, 6), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iters):\n\u001b[1;32m      7\u001b[0m     gap_length \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandrange(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mtraining_loop_association\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_comb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgap_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgap_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mban_comb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreserved_combs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m print_sep \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m1\u001b[39m, i, loss\u001b[38;5;241m/\u001b[39mprint_sep)\n",
      "File \u001b[0;32m~/Code/Personal/working_memory_experiment/model_test_functions.py:63\u001b[0m, in \u001b[0;36mtraining_loop_association\u001b[0;34m(model, num_bits, comb_num, learning_length, gap_length, recall_length, do_comb, ban_comb, do_print, do_train)\u001b[0m\n\u001b[1;32m     61\u001b[0m inputs, label \u001b[38;5;241m=\u001b[39m make_association_game(num_bits, comb_num, learning_length, gap_length, recall_length, do_comb, ban_comb)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 63\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m do_print:\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28mprint\u001b[39m(inputs, tf\u001b[38;5;241m.\u001b[39mround(result \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m, label)\n",
      "File \u001b[0;32m~/miniconda3/envs/working_memory_experiment/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Code/Personal/working_memory_experiment/working_memory_model.py:39\u001b[0m, in \u001b[0;36mWorkingMemoryModel.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_layers:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prev_layer, InnerMemoryLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, InnerMemoryLayer):\n\u001b[0;32m---> 39\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         out \u001b[38;5;241m=\u001b[39m layer(out)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling WorkingMemoryModel.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <InnerMemoryLayer name=inner_memory_layer, built=True> (of type <class 'inner_memory_layer.InnerMemoryLayer'>)\u001b[0m\n\nArguments received by WorkingMemoryModel.call():\n  • inputs=tf.Tensor(shape=(24, 6), dtype=float32)"
     ]
    }
   ],
   "source": [
    "print_sep = 10\n",
    "\n",
    "model.update_learning_rate(0.0005)\n",
    "iters = 10000\n",
    "loss = 0\n",
    "for i in range(iters):\n",
    "    gap_length = random.randrange(6, 9)\n",
    "    loss += float(training_loop_association(model, num_bits, num_comb, gap_length=gap_length, ban_comb=reserved_combs))\n",
    "    if (i+1) % print_sep == 0:\n",
    "        print(1, i, loss/print_sep)\n",
    "        loss = 0\n",
    "model.save_weights(\"checkpoints/association_H_checkpoint_1.ckpt\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sep = 10\n",
    "\n",
    "model.update_learning_rate(0.0005)\n",
    "iters = 10000\n",
    "loss = 0\n",
    "for i in range(iters):\n",
    "    gap_length = random.randrange(6, 9)\n",
    "    loss += float(training_loop_association(model2, num_bits, num_comb, gap_length=gap_length, ban_comb=reserved_combs))\n",
    "    if (i+1) % print_sep == 0:\n",
    "        print(1, i, loss/print_sep)\n",
    "        loss = 0\n",
    "model.save_weights(\"checkpoints/association_NH_checkpoint_1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sep = 10\n",
    "\n",
    "model.update_learning_rate(0.0002)\n",
    "iters = 20000\n",
    "loss = 0\n",
    "for i in range(iters):\n",
    "    gap_length = random.randrange(8, 13)\n",
    "    loss += float(training_loop_association(model, num_bits, num_comb, gap_length=gap_length, ban_comb=reserved_combs))\n",
    "    if (i+1) % print_sep == 0:\n",
    "        print(2, i, loss/print_sep)\n",
    "        loss = 0\n",
    "model.save_weights(\"checkpoints/association_H_checkpoint_2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sep = 10\n",
    "\n",
    "model.update_learning_rate(0.0001)\n",
    "iters = 20000\n",
    "loss = 0\n",
    "for i in range(iters):\n",
    "    gap_length = random.randrange(12, 19)\n",
    "    loss += float(training_loop_association(model, num_bits, num_comb, gap_length=gap_length, ban_comb=reserved_combs))\n",
    "    if (i+1) % print_sep == 0:\n",
    "        print(3, i, loss/print_sep)\n",
    "        loss = 0\n",
    "model.save_weights(\"checkpoints/association_H_checkpoint_3.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.         1.         0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         1.         0.         0.        ]\n",
      " [0.19501883 0.85006124 0.880332   0.19223347 0.6165452  1.        ]\n",
      " [0.00310924 0.2679704  0.21190816 0.7207948  0.83216214 1.        ]\n",
      " [0.48364595 0.18898124 0.48759508 0.8632275  0.53524876 1.        ]\n",
      " [0.96325105 0.30186686 0.66533905 0.6252739  0.76437634 1.        ]\n",
      " [0.62269336 0.11229911 0.43710333 0.2845461  0.9713798  1.        ]\n",
      " [0.07892009 0.35688958 0.57833004 0.1968443  0.23537217 1.        ]\n",
      " [0.58145535 0.27215368 0.31508553 0.19359636 0.61047286 1.        ]\n",
      " [0.78602165 0.67745596 0.71580565 0.45017314 0.37396136 1.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]], shape=(24, 6), dtype=float32) tf.Tensor(\n",
      "[[0.02 0.93 0.04 0.67 0.01]\n",
      " [0.21 0.66 0.18 0.53 0.16]\n",
      " [0.15 0.69 0.19 0.54 0.14]\n",
      " [0.14 0.7  0.18 0.55 0.14]\n",
      " [0.14 0.7  0.18 0.55 0.14]\n",
      " [0.15 0.7  0.17 0.55 0.14]\n",
      " [0.15 0.7  0.16 0.55 0.13]\n",
      " [0.15 0.7  0.15 0.54 0.13]\n",
      " [0.01 0.   0.07 0.   0.  ]\n",
      " [0.02 0.05 0.06 0.04 0.01]\n",
      " [0.02 0.03 0.08 0.03 0.01]\n",
      " [0.01 0.02 0.06 0.03 0.01]\n",
      " [0.01 0.02 0.04 0.03 0.01]\n",
      " [0.01 0.02 0.05 0.03 0.01]\n",
      " [0.01 0.03 0.03 0.03 0.01]\n",
      " [0.01 0.02 0.04 0.02 0.01]\n",
      " [0.13 0.74 0.09 0.6  0.14]\n",
      " [0.15 0.69 0.17 0.56 0.14]\n",
      " [0.16 0.68 0.16 0.54 0.14]\n",
      " [0.16 0.68 0.16 0.54 0.13]\n",
      " [0.16 0.68 0.16 0.55 0.13]\n",
      " [0.16 0.68 0.16 0.55 0.13]\n",
      " [0.16 0.68 0.17 0.55 0.13]\n",
      " [0.16 0.69 0.17 0.55 0.13]], shape=(24, 5), dtype=float32) tf.Tensor(\n",
      "[[0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]], shape=(24, 5), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.047411297>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset_memory()\n",
    "training_loop_association(model, num_bits, num_comb, gap_length=8, do_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x251d6074eb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.save_weights(\"checkpoints/testa0_checkpoint.ckpt\")\n",
    "\n",
    "\n",
    "# inputs, label = make_association_game(num_bits, num_comb, gap_length=4)\n",
    "# model.empty_build(inputs)\n",
    "# model.load_weights(\"checkpoints/testaWORKS_checkpoint.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_memory_experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
